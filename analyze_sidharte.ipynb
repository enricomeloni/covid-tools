{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "d:\\GitHub\\covid-tools\\regioni_sidarthe\n"
    }
   ],
   "source": [
    "results_path = os.path.join(os.getcwd(), \"regioni_sidarthe\") #, \"sidarthe\", \"Italy\")\n",
    "experiments = [dir for dir in os.listdir(results_path) if os.path.isdir(os.path.join(results_path, dir))]\n",
    "print(results_path)\n",
    "\n",
    "exps = {}\n",
    "for exp_dir in experiments:\n",
    "    json_path = os.path.join(results_path, exp_dir, \"final.json\")\n",
    "    if os.path.exists(json_path):\n",
    "        with open(json_path) as json_file:\n",
    "            exps[exp_dir] = json.load(json_file)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Best exp name: 52260e50-c7e4-45cb-b3b6-e11b1b51335a\nSettings used: \n{\n    \"region\": \"Italy\",\n    \"initial_values\": {\n        \"alpha\": 0.6,\n        \"beta\": 0.11,\n        \"gamma\": 0.7,\n        \"delta\": 0.11,\n        \"epsilon\": 0.171,\n        \"theta\": 0.371,\n        \"xi\": 0.017,\n        \"eta\": 0.125,\n        \"mu\": 0.017,\n        \"nu\": 0.027,\n        \"tau\": 0.01,\n        \"lambda\": 0.034,\n        \"kappa\": 0.017,\n        \"zeta\": 0.125,\n        \"rho\": 0.034,\n        \"sigma\": 0.017\n    },\n    \"learning_rates\": {\n        \"alpha\": 1e-05,\n        \"beta\": 1e-05,\n        \"gamma\": 1e-05,\n        \"delta\": 1e-05,\n        \"epsilon\": 1e-05,\n        \"theta\": 1e-07,\n        \"xi\": 1e-05,\n        \"eta\": 1e-05,\n        \"mu\": 1e-05,\n        \"nu\": 1e-05,\n        \"tau\": 1e-07,\n        \"lambda\": 1e-05,\n        \"kappa\": 1e-05,\n        \"zeta\": 1e-05,\n        \"rho\": 1e-05,\n        \"sigma\": 1e-05\n    },\n    \"target_weights\": {\n        \"d_weight\": 1.0,\n        \"r_weight\": 12.5,\n        \"t_weight\": 5.0,\n        \"h_weight\": 1.0,\n        \"e_weight\": 0.0\n    },\n    \"train_size\": 46,\n    \"val_len\": 20,\n    \"der_1st_reg\": 31000.0,\n    \"t_inc\": 1.0,\n    \"m\": 0.125,\n    \"a\": 0.05,\n    \"integrator\": \"Heun\",\n    \"loss_type\": \"rmse\",\n    \"started\": \"31/May/2020 22:16:54\"\n}"
    }
   ],
   "source": [
    "validation_key = \"rmse\"\n",
    "\n",
    "df = pd.DataFrame()\n",
    " \n",
    "#for exp_name, exp in exps.items():\n",
    "def selector(k):\n",
    "    tot_loss = 0.\n",
    "    for loss in \"dehrt\":   \n",
    "        item = exps[k][\"val_risks\"][f\"{loss}_rmse\"]\n",
    "        tot_loss += item[0] if isinstance(item, list) else item\n",
    "    return tot_loss\n",
    "\n",
    "best_exp = min(exps, key=selector)\n",
    "\n",
    "print(f\"Best exp name: {best_exp}\")\n",
    "print(\"Settings used: \")\n",
    "with open(os.path.join(results_path, best_exp, \"settings.json\")) as settings_file:\n",
    "    for line in settings_file.readlines():\n",
    "        print(line, end='')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import torch\n",
    "# get references\n",
    "references = {}\n",
    "param_keys = ['alpha', 'beta', 'gamma', 'delta', 'epsilon', 'theta', 'xi', 'eta', 'mu', 'nu', 'tau', 'lambda', 'kappa', 'zeta', 'rho', 'sigma']\n",
    "ref_df = pd.read_csv(os.path.join(os.getcwd(), \"regioni\", \"sidarthe_results.csv\"))\n",
    "for key in 'sidarthe':\n",
    "    references[key] = ref_df[key].tolist()\n",
    "\n",
    "for key in [\"r0\", \"h_detected\"]:\n",
    "    references[key] = ref_df[key].tolist()\n",
    "\n",
    "for key in param_keys:\n",
    "    references[key] = ref_df[key].tolist()\n",
    "\n",
    "for k,v in references.items():\n",
    "    references[k] = torch.tensor(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [],
   "source": [
    "#extract targets\n",
    "\n",
    "from utils.data_utils import select_data\n",
    "\n",
    "df_file = os.path.join(os.getcwd(), \"COVID-19\", \"dati-andamento-nazionale\", \"dpc-covid19-ita-andamento-nazionale.csv\")\n",
    "area = [\"ITA\"]\n",
    "area_col_name = \"stato\"  # \"Country/Region\"\n",
    "\n",
    "groupby_cols = [\"data\"]  # [\"Date\"]\n",
    "\n",
    "d_col_name = \"isolamento_domiciliare\"\n",
    "r_col_name = \"ricoverati_con_sintomi\"\n",
    "t_col_name = \"terapia_intensiva\"\n",
    "h_detected_col_name = \"dimessi_guariti\"\n",
    "e_col_name = \"deceduti\"  # \"Fatalities\"\n",
    "\n",
    "x_target, d_target = select_data(df_file, area, area_col_name, d_col_name, groupby_cols, file_sep=\",\")\n",
    "_, y_target = select_data(df_file, area, area_col_name, \"totale_positivi\", groupby_cols, file_sep=\",\")\n",
    "_, r_target = select_data(df_file, area, area_col_name, r_col_name, groupby_cols, file_sep=\",\")\n",
    "_, t_target = select_data(df_file, area, area_col_name, t_col_name, groupby_cols, file_sep=\",\")\n",
    "_, h_detected_target = select_data(df_file, area, area_col_name, h_detected_col_name, groupby_cols, file_sep=\",\")\n",
    "_, e_target = select_data(df_file, area, area_col_name, e_col_name, groupby_cols, file_sep=\",\")\n",
    "\n",
    "initial_len = len(y_target)\n",
    "tmp_d, tmp_r, tmp_t, tmp_h, tmp_e = [], [], [], [], []\n",
    "for i in range(initial_len):\n",
    "    if y_target[i] > 0:\n",
    "        tmp_d.append(d_target[i])\n",
    "        tmp_r.append(r_target[i])\n",
    "        tmp_t.append(t_target[i])\n",
    "        tmp_h.append(h_detected_target[i])\n",
    "        tmp_e.append(e_target[i])\n",
    "d_target = tmp_d\n",
    "r_target = tmp_r\n",
    "t_target = tmp_t\n",
    "h_detected_target = tmp_h\n",
    "e_target = tmp_e\n",
    "\n",
    "targets = {\n",
    "    \"d\": d_target,\n",
    "    \"r\": r_target,\n",
    "    \"t\": t_target,\n",
    "    \"h_detected\": h_detected_target,\n",
    "    \"e\": e_target\n",
    "}\n",
    "\n",
    "for k,v in targets.items():\n",
    "    targets[k] = torch.tensor(v, dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "{'d': tensor(39365.4023), 'r': tensor(13762.4814), 't': tensor(1717.9193), 'h_detected': tensor(35828.5469), 'e': tensor(13273.6357)}\nTheir loss: 103947.9765625\nOur loss: 27381.093587485906\n"
    }
   ],
   "source": [
    "def rmse_loss(target, hat):\n",
    "    return torch.sqrt(\n",
    "        0.5 * torch.mean(\n",
    "            torch.pow(target - hat, 2)\n",
    "        )\n",
    "    )\n",
    "\n",
    "losses = {}\n",
    "tot_loss = 0.\n",
    "for k,v in targets.items():\n",
    "    loss = rmse_loss(targets[k], references[k][0:targets[k].size(0)])\n",
    "    losses[k] = loss\n",
    "    tot_loss += loss\n",
    "\n",
    "our_losses = {}\n",
    "for loss in \"dehrt\":   \n",
    "        item = exps[best_exp][\"val_risks\"][f\"{loss}_rmse\"]\n",
    "        our_losses[loss] = item[0] if isinstance(item, list) else item\n",
    "\n",
    "print(losses)\n",
    "\n",
    "print(f\"Their total loss: {tot_loss}\")\n",
    "print(f\"Our total loss: {selector(best_exp)}\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python37664bitcovidtoolscondaed93c0ad89524ea5ad4f4946bde80980",
   "display_name": "Python 3.7.6 64-bit ('covid-tools': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}